Part 1 Report

Overall part 1 of this project was very easy and self explanatory. Before starting anything, I downloaded all of the files (WordCount.java, canterbury.zip, wiki-micro.txt) and watched the video that was posted. Initially seeing that the project was due the day we came back from spring break, I took the break as an opportunity to start on the project and come to office hours (on 3/4) with questions. After the due date changed, I still followed my original plan to prevent procrastinating.
Initially I did have some problems uploading files. Eventually I figured out I needed to use a different terminal for uploading/downloading from the cluster. The only other big issue I had with part 1 was navigating the file systems on the cloud. It took a little bit to get use to /user/ vs /users/. But After rereading the pdf and some quick ls commands, I was able to understand /user/ was for the 'hadoop fs' commands, and /users/ was for upload/download and the default directory when you initially ssh into the cluster.

Part 2 Report

Project two definitely came with some problems. Initially it was difficult for me to concatenate the word with even just the delimiter. I was trying to do this in the new Text constructor (currentWord = new Text(word + "#####");). After the compilation failed I also tried to use the String.concat method (currentWord = new Text(word.concat("#####"));). This also failed. When I got to office hours on 3/4 the TA was a HUGE help on getting my concatenation the right way out of the new Text constructor (word = word + "#####";). He also talked me through the program's process and helped me understand what each part was doing. He pointed me in the direction of the InputSplit and after a quick google search I had the file name to add onto the word. 
The next difficulty I had was naming the new file DocWordCount.java. This was because when initially using the '$hadoop jar wordcount.jar org.apache.hadoop.examples.DocWordCount /user/<username>/input /user/<username>/output' command, I kept getting an error that DocWordCont did not exist. I changed the path 'org.apache.hadoop.examples.WordCount' to 'org.apache.hadoop.examples.DocWordCount' just as I had added 'Doc' to the other commands WordCount was used for part 1. I went back to using the original path (org.apache.hadoop.examples.WordCount) which ran, but gave me the incorrect output; I kept getting the output from part 1. I thought this problem was because the concatenation not working, however a group of students made a breakthrough at the office hours on 3/9. Someone mentioned using a different path: 'org.myorg.DocWordCount'. I tried this edit hopefully and, SUCCESS. I got output with the delimiter and the filenames attached!